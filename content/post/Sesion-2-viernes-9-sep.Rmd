---
title: "Sesión 2 viernes 9 Septiembre"
author: "JLMR"
date: 2022-09-04T22:13:14-05:00
output: html_document
---



```{r}
library(tidyverse)
```



```{r set-global-options, echo=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(eval = TRUE, 
                      echo = TRUE, 
                      cache = FALSE,
                      include = TRUE,
                      collapse = FALSE,
                      dependson = NULL,
                      engine = "R", # Chunks will always have R code, unless noted
                      error = FALSE)                     

```



```{r silent-packages, echo = FALSE, eval = TRUE, message=FALSE, include = FALSE}

library(ggrepel)
library(tidyverse)
library(scales)
library(ggpubr)
library(plotly)
library(foreign)
library(datagovindia)
```

## Objetivos: 

Estudiar las medidas de tendencia central y dispersión.    

### Meta de aprendizaje: 
Implementar la estimación y representar visualmente las estimaciones usando R, Python. 

#### Contexo:  
Estadística descriptiva.


#### Definiciones.


Una pregunta básica para entender un fenómeno a escala regional es 

¿Qué tan frecuente ocurre un suceso? 

Por ejemplo podemos estar interesados en comprender la distribución del ingreso.

¿ Cuál es el ingreso promedio en México?

Estas y otras preguntas requieren del análisis de datos  y las medidas de tendencia central nos ayudan a obtener esta información.

### Media

El dato representativo, el promedio. 

**Notación:**

Media muestral:

$$\bar{X}=\frac{1}{n} (\sum_{i=1}^{n} x_i) =\frac{x_1 +x_2+...+x_n}{n}$$
Media poblacional con la letra griega:
$$\mu$$


Ejemplo  1

```{r}

# Defining vector
x <- c(3, 7, 5, 13, 20, 23, 39, 23, 40, 23, 14, 12, 56, 23)

# Print mean
print(mean(x))
```

### Media geométrica.

La media geométrica de una serie que contiene **n** elementos esta dada por:  

La raíz $n$ del producto de los elementos.

![](/img/geomed.jpg)
![](/img/geometrica.jpg)


Su aplicación se dirige a datos que tienen una naturaleza de 
**crecimiento exponencial** por ejemplo que
exhiben correlación serial, (dato en momento del tiempo t  que depende del dato en el momento t-1)
esto es por ejemplo común en el 
campo series de tiempo en economía y el area de las finanzas. Ejemplo, la tasa de crecimiento del PIB, la inflación, etc., 

Este tipo de variables no tiene un comportamiento aleatorio, pero sus observaciones son dependientes de los valores que tome la variable en momentos previos (lags.). 

**NOTE:** 

+ El valor de la media geométrica es siempre menor que la media aritmética.

+ Unicamente para valores positivos.
Dado el algoritmo de estimación, en los números reales no
esta definida la raíz  para 
números negativos. 

##### Ejemplo 1

Estime la media aritmética y geométrica para el ingreso percápita de los países para el año 1952 y 2007.  Base de datos de ingreso percapita mundial. 


```{r}

ingreso <- (data.frame(y=c(3, 7, 5, 13, 20, 23, 39, 23, 40, 23, 14, 12, 56, 23,"nd")))

nums <- as.numeric(as.character(ingreso$y))

m <- mean(nums, na.rm = T)


## SOLUCION.

## Paso 1 Cargamos las datos 

library(gapminder)
datos<-gapminder 

## Paso 2  vemos los datos, la estructura los nombres de variables 

view(datos)
names(datos)
glimpse(datos)

## paso 3  filtramos el año requerido

media_1952<-datos%>%filter(year=="1952")

## Paso 4  hacemos el cálculo usando la función summarise y mean. 

m_52<-summarise(media_1952,m=mean(gdpPercap))

```

```{r, include=FALSE}
## SOLUCION para año 2007.

media_2007<-datos%>%filter(year=="2007")
m_07<-summarise(media_2007,m=mean(gdpPercap))

## SOLUCIÓN MEDIA GEOMÉTRICA.


# Paso 1 Cargamos el paquete psych. este contiene la función para estimar la media geométrica.

library(psych)

# Paso 2 Procedimiento manual, calculamos el logaritmo, luego la media aritmética de esos valores y finalmente convertimos de logaritmo a niveles. (elevamos  la base "e" a la potencia indicada).

## Método paso a paso. 

## Creo columna con logaritmos de x y estimo la media para luego estimar el antilogaritmo. con "exp".

datosejemplo<-mutate(media_1952, logs=log(gdpPercap),medialogs=mean(logs), m52=exp(medialogs))

## Método resumido.

exp(mean(log(media_1952$gdpPercap)))

## Método directo con la función geometric.mean

geometric.mean(media_1952$gdpPercap)

```

Realice la estimación para 2007.

¿Qué podemos decir de la variación en el nivel de ingreso entre los países de la muestra en el periodo de **1952** a **2007**. ¿Cuál es la tasa de crecimiento?


##### Ejercicio 1 Estime la media aritmética y geométrica para las variables población y esperanza de vida por continente.


```{r, include=FALSE}
library(psych)

#geometric.mean(exa$ingreso.x)

#media_geo<-exp(mean(log(exa$ingreso.x)))

#media_geo

## Note que, en primera instancia estimamos el logaritmo de la variable  ingreso. La estimación del logaritmo permite tomar en consideración la naturaleza de crecimeinto exponencial que tiene este variable en particular.
## Tal como el algoritmo de estimación de media geométrica indica, obtenemos la media aritmética de los logaritmos y posteriormente reexpresamos el indicador a niveles, es decir no expresados en logaritmos.

#vNote que el cálculo usa la base de logaritmo natural que es tomando como base el número e=2.718281828....```
```

Para estimación en python See **Sesión2_tendencia central.ipynb**


### Mediana.

El valor que se localiza en la mitad de los datos cuando los datos se ordenan (ej. ascendente).

En contraste con la media, **la mediana** no es afectada por los puntos extremos.

La **mediana** es representativa  de la tendencia central cuando los datos no tienen una distribución simétrica. (cuando los datos tienen sesgo) Una expresión del sesgo es cuando la media y la mediana no son iguales. 

En este caso es  preferible la **mediana** como indicador representativo de tendencia dentral.
 
 
 Ejemplos de distribución con sesgo. 
 
![](/img/normal_.jpg)
 
*Improve your skills*[visualization training material](https://r-graphics.org/recipe-distribution-basic-density)
 
#### Ejemplo 3

```{r}
 # Defining vector
x <- c(3, 7, 5, 13, 20, 23, 39,
	23, 40, 23, 14, 12, 56, 23)

# Print Median
median(x)
```




## Moda

El valor que ocurre con mayor frecuencia en la distribución.

```{r}

# Defining vector
x <- c(3, 7, 5, 13, 20,  39, 23, 40,
	23, 14, 12, 56, 23, 29, 56, 37,
	45, 1, 25, 8, 56, 56)

# Generate frequency table
y <- table(x)

# Print frequency table
print(y)

# Mode of x

moda <- names(y)[which(y == max(y))]

# Print mode
print(moda)
```

Implementación en **R**


Dado un conjunto de datos cualquiera, podemos determinar las medidas de tendencia central aplicando la función (verbo) **summary** sobre el objeto (data frame deseado  -sustantivo-).



Ver Práctica de implementación en **Sesión2_tendencia central.ipynb**



##### Ejemplo 1 

**Estimación de medidas de tendencia central básicas.** 

**Datos:** Correlación entre Salario medio y participación de la Mujer por categoría de ocupación.


Buscamos deteminar el comportamiento del salario percibido entre un grupo de egresados universitarios de diversas disciplinas.

La base de datos contiene diversas características de la población de estudio incluido el salario (una varible numérica ordinal) y la variable que describe la disciplina en la que trabaja el individuo. 


La meta es estimar los salarios promedio para cada grupo ocupacional, así como representar graficamente el comparativo.

```{r, include=FALSE}

# install.packages("datagovindia")

library(datagovindia)

url<-"https://github.com/bordercode/STATISTICS-I-MDR/blob/main/content/english/blog/graduados.rds?raw=true"

ejercicio_1<-read_rds_from_github(url)

```

```{r, message = FALSE, warning = FALSE, fig.width=10, fig.height=6, echo= TRUE}

## Remember to have loaded library(datagovindia)

# Cargamos los datos.
# get data using code chunk above.

## from url

url_grad<-("https://github.com/JoseLuisManzanaresRivera/intersemestral-2021/blob/main/content/post/graduados.rds?raw=true")

graduados<-read_rds_from_github(url_grad)


## Local  load 



# Exploración básica para conocer la estructura.

glimpse(graduados)

# Tipo de estructura de datos: Corte transversal (un momento en el tiempo).

# Con 64 observaciones. 21 variables.  Este formato de observacion por renglon y variable por columna lo denominaresmo -tidy data- o datos organizados con estructura estándar.

# Visualización  Scatter con trend para  4 features.  X= Proporcion mujeres/hombres por categoria, Y=mediana del salario, Categoria en color y otra Categoria en point size.

## Observamos variables numéricas, (denotadas int o dbl según sean numeros enteros o decimales), categóricas (denotadas fct).  Otro tipo de datos que no esta presente paro es comun es chr, (string de texto, ejemplo nombre de países, calles, etc.)


# Alternativa  para conocer la estructura de datos. Desventaja si son muchas variables es una gran tabla. 

str(graduados)

# Medidas de tendencia central y estadistica descriptiva básica.

summary(graduados)


 g<-ggplot(graduados,aes(ShareWomen,Median, color=Area,size=Sample_size, label=Major))+
  geom_point()+
  geom_smooth(aes(group=1),method = "lm")+
  expand_limits(y=0)+
  scale_color_brewer(palette="Dark2")+
  scale_y_continuous(labels=dollar_format())+
  scale_x_continuous(labels=percent_format())+
  labs(x="Mujeres/Hombres", y="Salario Medio  US$")+
    theme(legend.position="botton")+
   theme_light()
  
   ggplotly(g)

```


**Nota**: Como parte del proceso de los datos no solo estimamos la media  pero desplegamos una herramienta de viasualización denominado **Diagrama de Dispersión**  (representación gráfica) **bi-variada** 

Con la libreria ggplot de R podemos también representar este conjunto de datos  mediante el  diagrama de dispersión incorporando más dimensiones (no solo el salario y la proporción entre mujeres y hombres), pero también la categoria a la que corresponde la ocupación y el tamaño de la muestra, Lo anterior permite extraer una gran cantidad de información para perfilar alguna explicación o hipótesis sobre el fenómeno.

Estamos describiendo los datos, estamos haciendo análisis exploratorio de datos!

## Medidas de Dispersón: 

## Percentiles

Una pregunta muy frecuente cuando analizamos la distribución de los datos es ¿Qué porcentaje de los datos se encuentra por debajo de cierto umbral? 

Por ejemplo si la base contiene ingresos percapita nos podemos preguntar ¿Cuál es el nivel de ingreso por debajo del cuál se ubica el 60% de la población? 

Si estimamos el percentil 60, tenemos la respuesta a esta pregunta.

La estimación de los percentiles es informativa del grado de concentración de los datos hacia un valor particular. 

Por ejemplo, si estamos analizando la distribución de ingreso, nos puede interesar determinar que porcentaje de los datos presentan un ingreso igual o inferior a la linea de pobreza (este umbral es un dato particular *x*  de la variabe **X**).


#### Ejemplo 1 

Estimación de los percentiles p25, p50, p75. Estos percentiles en  particular corresponden con los cuantiles que de hecho dividen los datos en 4 partes Q1=.25, Q2=.50, Q3=.75, Q4=1.

```{r}
### Generamos una muestra aleatoria de 1000 observaciones para simular ingresos en un rango de 5000 a 60000 mensuales.  Note usamos función "runif". otras funciones  utiles para generar numeros aleatorios son r.norm().

ingresos<-data.frame(pesos=runif(1000, min=5000, max=60000))

# Paso 2. Aplicamos la función quantile para la variable de interes, note que la función admite dos argumentos, el primero, el objeto x y el segundo denominado probs. para definir el percentil de interés. Por default la función estima Q0  a Q4.
 
quantile(ingresos$pesos)
```


#### Ejercicio  1. 

Determine los cuantiles Q1, Q2, Q3, Q4 para la variable esperanza de vida (lifexp) expresada en años para la informacón por continente.

¿Qué continente tiene la mayor esperanza de vida considerando al menos el 75% de los datos disponibles.  (ej. ¿Qué continente tiene el mayor  **Q3**)?.

¿Cuál es la diferencia  entre el **Q1** de **Africa** y **Q1** del continente con mayor esperanza de vida?


```{r }
library(gapminder)

cuantiles<-gapminder

Africa<-cuantiles%>%filter(continent=="Africa")
quantile(Africa$lifeExp)  

### Interpretación. 

#Q0 mide el dato de menor valor de la base. 

#Q1 Indica que el 25% de los datos tiene una lifeExp de 42.3725 años o menos. 

#Q2 Indica  que  el 50% de la pobalción tiene un 
#lifeExp de 47.7920 o menos años.

#Q3 Indica  que  el 75% de la pobalción tiene un 
#lifeExp de 54.4115 o menos años.

#Q Indica  que  la mayor lifeExp en los paises de la muestra (Africa) es 75.4420 años.

Americas<-cuantiles%>%filter(continent=="Americas")
quantile(Americas$lifeExp)  

Asia<-cuantiles%>%filter(continent=="Asia")
quantile(Asia$lifeExp)  
 
Europa<-cuantiles%>%filter(continent=="Europe")
quantile(Europa$lifeExp)

Oceania<-cuantiles%>%filter(continent=="Oceania")
quantile(Oceania$lifeExp)

```


```{r}

## Estimación alternativa usando tidyverse aproach. 


## Paso 1 definimos el vector que contiene los percentiles que nos interesan, en este caso  deseamos calcular los cinco cuantiles desde Q0 a Q4.

q=c(0,.25,.5,.75,1)

## Paso 2, agrupamos los datos por continente, (recuerde es una variable categ[orica  "factor". Finalmente usamos el verbo summarize para hacer la estimación de los percentiles. Ete calculo se base en la función quantile que toma los argumentos lifeExp y  probs en donde definimos el la columna del vector donde almacenamos los percentiles a estimar )

estimado<-cuantiles%>%
  group_by(continent) %>%
  summarize(
    percentil0 =  quantile(lifeExp, probs =q[1]),
    percentil25 = quantile(lifeExp, probs = q[2]),    percentil50 = quantile(lifeExp, probs = q[3]),    percentil75 = quantile(lifeExp, probs = q[4]),
   percentil100 = quantile(lifeExp, probs = q[5]))
```

##### Ejercicio asignación para casa.

Estime los percentiles 30, 60, 90 para la variable ingreso en el año 1952 y 2007 para los países de los continentes  Africa y  Asia. 

Indique brevemente sus observaciones.


#### Rango

Una de las medidas más sencillas para medir la dispersión en la distribución de los datos es mediante la diferencia entre el dato maximo y el mínimo, este indicador se denomina **Rango **

En la estimación del rango se debe tener cuidado con la presencia de outliers (datos extremos o atípicos).


Para tener una idea de la dispersión de los datos, es común estimar el **rango intercuartil** que marca la distancia entre el dato en el percentil 25 y el 75.

En la práctica, el percentil 25 se denomina  **Q1**  o primer cuartil y el percentil 75 se denomina cuartil 3 o **Q3**. 

La estimación del rango intercuartil es comunmente usada como prueba para detectar valores extermos  (**outliers**). 

El criterio de decisión indica que se tiene un outlier si un dato se ubica sobre 1.5 IQR respecto a los limites definidos por  el **Q1** y el **Q3**. 

![](/img/d.jpg)

#### Representación gráfica de la frecuencia.


Un punto de partida básico es mediante la exploración de la frecuencia. Veamos como podemos generar un tabla de frecuencia para conocer la distribución de un conjunto de datos hipotético:
 
 
 
```{r}
# Defining vector
x <- c(3, 7, 5, 13, 20, 23, 39, 23, 40,
	23, 14, 12, 56, 23, 29, 56, 37,
	45, 1, 25, 8, 56, 56)

# Generate frequency table
y <- table(x)

# Print frequency table
print(y)

```


Podemos representar esta información mediante diversas visualizaciónes: 

Tres de las más importantes son:

- **Histogramas**

- **Funciones de Densidad (KDF)**

- **Box plot**


### Histograma

Esta es una representación   visual que integra la frecuencia con la ocurre una determinada observación. (Nota: Es una representación para datos discretos, no contínuos) 

Se compone por la suma de la frecuencia observada entre grupos predefinidos.

La estimación considera dos parámetros: El número de grupos o clases  (bins, barras que integran el histograma) y el ancho de clase. 

Para estimar el primer parámetro, consideramos la raíz cuadrada del número de obsrevaciones en el conjunto de datos.

Para estimar el ancho de clase, dividimos el rango entre el número de clases (bins).

**Contexto**. Creación de histograma para representar la frecuencia de los datos. 

Ir a **.ipynb** file

##### Ejemplo 1

```{r, warning = FALSE}

### Load data. contiene registros de nacimientos con sindrome de dificultad respiratoria. MX, Variables de interés, peso y tipo de parto.  ej cesarea o eutócico.


## from URL

url<-("https://raw.githubusercontent.com/JoseLuisManzanaresRivera/intersemestral-2021/main/content/post/sindrome.csv")

peso<-read.csv(url)

## Hacemos la revision de rutina. 
names(peso)
view(peso)
str(peso)
glimpse(peso)
summary(peso)

```

```{r, include=FALSE}

#N16<-readRDS("N16.rds")
#glimpse(N16)

#p220<-select(N16,cve_cie, ent_nac, con_indm,aten_pren,niv_escol,sexoh,tallah,pesoh,apgarh,silverman,procnac,edad_madre )%>%mutate(sdr=ifelse(cve_cie=="P220"|cve_cie=="P229",1,0), sexoh=as.factor(sexoh))%>%filter(pesoh!=9999, tallah!=99,sdr==1, sexoh!=9,edad_madre!=999, procnac!=9&procnac!=3&procnac!=8&procnac!=4, apgarh<=10, silverman<=10)%>%mutate(proc_n=ifelse(procnac==1,"Eutócico","Cesárea"))%>%rename(Procedimiento=proc_n)

#write.csv(p220,"sindrome.csv")
# getwd()

## p220_no_sdr<-select(N16,cve_cie, ent_nac, con_indm,aten_pren,niv_escol,sexoh,tallah,pesoh,apgarh,silverman,procnac,edad_madre )%>%mutate(sdr=ifelse(cve_cie=="P220"|cve_cie=="P229",1,0), sexoh=as.factor(sexoh))%>%filter(pesoh!=9999, tallah!=99,sdr!=1, sexoh!=9,edad_madre!=999, procnac!=9&procnac!=3&procnac!=8&procnac!=4, apgarh<=10, silverman<=10)%>%mutate(proc_n=ifelse(procnac==1,"Eutócico","Cesárea"))%>%rename(Procedimiento=proc_n)
```

```{r}

### Paso 2 Hacemos el Histogramo. Note que la variable en el eje x es el peso. Por default la variable en Y es la frecuencia en este caso el número de casos.

# Nota2: observe que usamos la función facet_grid  para indicar que necesitamos los histogramas agrupados para la variable categorica  procedimiento.

h1<-ggplot(peso, aes(x=pesoh)) + geom_histogram(fill="white", colour="black") +
facet_grid(Procedimiento~ .)+xlab("Peso (gramos)")+ylab("Casos")


### Representación alternatica con los histogramas en un solo plot, en este caso el parametro fill indica la variable categorixa que usaremos para representar los histogramas, en este caso se mostrarán en la misma grafica. Usamos el argumento identity para indiccar que necesitamos solo el histograma para la variable peso.

h2<-ggplot(peso, aes(x=pesoh, fill=Procedimiento)) +
geom_histogram(position="identity")+
xlab("Peso (gramos)")+ylab("Casos")+
scale_fill_manual(values=c("grey70", "grey20"))

```

```{r,echo= FALSE, fig.height = 8, fig.width = 12, warning=FALSE, message=FALSE}
h1
```

```{r,echo= FALSE, fig.height = 8, fig.width = 12, warning=FALSE, message=FALSE}
h2
```



Importante: La forma del histograma  (en cuanto a su simetría) permite informar sobre **el sesgo de los datos**. 

En la figura siguiente se observan dos esenarios relevantes: **Sesgo positivo**  y **negativo**. En ambos casos se tiene una implicación sobre el supuesto de normaliad de los datos. Recordemos que la simetría es una condición necesaria de una   **distribución normal.** 

Una particularidad adicional es que en ausencia de **normalidad**  (un concepto que revisaremos en la sesión sobre distribuciones de probabilidad) de los datos las medidas de tendencia central **media** y **mediana** difieren.


![](/img/qq1.jpg)

## Boxplot.

**Contextualización:** Contraste entre la distribución de grupos,  identificación de **outliers** y permite ubicar  el **rango inter-cuartil** y la **mediana**.

Esta representación visual de la distribución es generalmente utilizada para la representación de **variables categóricas**.

Note que los upper and **lower fences** o **whiskers**, se extienden por definición en un rango de +/- 1.5 IQ, pero la representación considera los puntos más alejados **dentro de este rango**, es decir, puede ser que el rango sea mayor a la ubicación concreta de los puntos en cada lado, es por ello que los **fences** comunmente no son simétricos respecto a los límites de la caja que forma el rango intercuartil.

### Representación de dispersión datos con frecuencia diaria. Boxplot

[Datos  site:](https://smn.conagua.gob.mx/es/climatologia/informacion-climatologica/normales-climatologicas-por-estado)
[Source alternariva](http://atlasclimatico.unam.mx/RRDM/)

![](/img/explicacion_bxplt.jpg)


**Ejemplo 1**  

Ver Sesion2.ipynb


**Ejemplo 2**

Estimación de box plot para examinar la distribución de una variable. Inclusión de s[olo una categoría. Distribución de temperaturas mínimas diarias registradas en estación metereológica **DGO10092** del SMN. Periodo 1941 -2000.

```{r,  fig.height = 8, fig.width = 12,  echo = FALSE, warning = FALSE}

### Paso 1 get data from url

urldgo<-"https://raw.githubusercontent.com/JoseLuisManzanaresRivera/intersemestral-2021/main/content/post/dgo_temp.csv"

dgo_temp<-read.csv(urldgo)
## Load data set form From local

#dgo_temp<-readRDS("dgo_temps.rds")

## Damos un vistazo a los datos para comprobar que las variables  estan en el formato apropiado para su análisis.


### Paso 2. Exploramos con el procedimiento estandar.
names(dgo_temp)
view(dgo_temp)
glimpse(dgo_temp)
str(dgo_temp)
```

```{r, include=FALSE}

## Notamos que la variable FECHA no esta declarada como clase "date", necesitamos hacer un mutate para corrgir esto antes de su uso.  
#Tip: Usamos la función as.Date respetando el orden de los datos como día, mes, año !!

#DGO<-dgo_temp%>%mutate(date=as.Date(FECHA, "%d/%m/%Y"))%>%mutate(ms=as.integer(substr(FECHA,4,5)),año=substr(FECHA,7,10))

## Creamos un data frame con dos variables: mes con el nombre del mes  y ms con el número del mes para agregarlo a la base original. Esto será necesario para su representación gráfica. 


#meses<-data.frame(mes=c("Enero ",	"Febrero",	"Marzo",	"Abril",	"Mayo",	"Junio",	"Julio",	"Agosto",	"Septiembre",	"Octubre",	"Noviembre",	"Diciembre"),ms=seq(1, 12, by=1))


### Usamos la función left_join para unir las dos bases de datos (data frames). 

#DGO<-left_join(meses,DGO)
##glimpse(DGO)
##levels(DGO$mes )
#write.csv(DGO, "dgo_temp.csv")

## Plot Daily  1941-2000
```

```{r}
## Paso 3. Creamos el Plot para cada mes con datos diarios en el periodo. 1941-2000

boxplot<-ggplot(dgo_temp,aes(x=fct_inorder(mes),y=tmin))+
geom_boxplot()+
xlab("Mes")+ylab("Temperatura diaria mínima°c")+
theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1))
```
#### Distribución de temperaturas mínimas  diarias registradas en estación metereológica DGO10092   del SMN. Periodo 1941 -2000. 
```{r, warning = FALSE}
boxplot
```

**Ejemplo 2:** 

Determinación de Media, rango intercualtil y percentiles 1 y 3 (q25 y q75). Representación con boxplot para variables tipo categoricas. 


```{r,  fig.height = 8, fig.width = 12, include=FALSE,  echo = FALSE, warning = FALSE}

#BC2001<-read.csv("ema_2001_AGUACALIENTE.csv")%>%rename(max=tmin,min=tmax)

#df<-BC2001%>%mutate(max=as.numeric(as.character(max)),min=as.numeric(as.character(min)) )

#temp<-mutate(df,date=as.Date(FECHA, "%d/%m/%Y"))%>%mutate(mes=as.integer(substr(FECHA,4,5)),año=substr(FECHA,7,10))

#tidy<-gather(temp, tipo, temperatura, max:min)


#meses<-data.frame(Meses=c("Enero ",	"Febrero",	"Marzo",	"Abril",	"Mayo",	"Junio",	"Julio",	"Agosto",	"Septiembre",	"Octubre",	"Noviembre",	"Diciembre"),mes=seq(1, 12, by=1))


#tidy_bc_temp<-left_join(tidy,meses)

#write.csv(tidy_bc_temp, "tidy_bc_temp.csv")
```

```{r}
## Paso 1 Load data
url_bc_temp<-"https://github.com/JoseLuisManzanaresRivera/intersemestral-2021/blob/main/content/post/tidy_bc_temp.csv?raw=true"


bc_tem<-read.csv(url_bc_temp)

## Paso 2  Make boxplot.

boxplot_2<-ggplot(bc_tem, aes(x=fct_inorder(Meses), y=temperatura)) + geom_boxplot(aes(fill=tipo))+
xlab("Mes")+
ylab("Temperatura diaria máxima y mínima°c")+
theme_light()+
theme(axis.text.x = element_text(angle=45, hjust=1, vjust=1))



```


```{r, warning = FALSE,message=FALSE, echo=FALSE}
library(plotly)
ggplotly(boxplot_2)
```







*Docucmentación adicional con ejemplos de repaso* [boxplot](http://www.cookbook-r.com/Graphs/Plotting_distributions_(ggplot2)/)

### Varianza

El valor promedio de las desviaciones al cuadrado de cada elemento *i*  respecto a la media.


$$V(X)= Var(X)=\sigma^2_{X}$$
$$\sigma^2_x = \frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{X})^2$$

O en términos de valor esperado tenemos: 
$$Var[X]=E[(X-E[X]^2)]$$
$$=E[X]^2-(E[X]^2)$$


La varianza es una referencia importante para determinar la dispersión de un conjunto de datos. Sin embargo, cuando queremos comparar las dispersión entre conjuntos de datos una deventaja de la varianza es que esta exprezada en **unidades al cuadrado**.  Es una medida de dispersión que depende de la escala de medición.


Esta desventaja la resuelve la **desviación estándar** que es una medida independiente de la escala.  Por este motivo la medida de dispersión clásica que utilizaremos para comparar la dispersión de los datos es la **desviación estádard**. 

### Desviación estándar. 

Raíz cuadrada de la varianza.

$$\sqrt{\sigma^2} = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{X})^2}=\sigma$$


Asociado a esta medida, podemos calcular **el coeficiente de variación** que solo añale la relación  de esta dispersión, medida por la desviación estándard respecto a la media. Este coeficiente se ubica en el rango 0-1 frecuentemente, pero en algunas distribuciones puede superar la unidad. 
$$cv=\frac{\sigma_x}{|\bar{X}|}$$
En términos generales entre mayor es el **cv**, tenemos una mayor dispersión en los datos. 




## Actividad 


Con los datos sobre temperatura disponibles sobre la temperatura por la estación meteorológica  en Tijuana, determine: 

+ ¿Qué valor toma la media, la mediana, Q1, Q3 y cuál es el rando intercuartil?

+ ¿Qué año presenta la mayor precipitación?




```{r}
url_tij<-("https://github.com/JoseLuisManzanaresRivera/intersemestral-2021/blob/main/content/post/precip_tijuana.csv?raw=true")

practica<-read_rds_from_github(url_tij)%>%
  na.omit()
```

```{r, include=FALSE}

### Paso 1 
precip<-group_by(practica,año)%>%
  summarise(mes=sum(mesp))

### Paso 2

summary(precip)
glimpse(precip)

## Convertimos variable año de Chr string a numérica.
precip<-mutate(precip,año=as.numeric(año))

### paso 3 plot Representación en line plot. 

plt<-ggplot(precip, aes(x=año, y=mes))+
geom_line(size=.3, colour="gray")+
geom_smooth()+
xlab("Año")+
ylab("Precipitación  promedio. 1969-2012 (mm)")+
theme_light()+
geom_hline(yintercept = 185.2, size=.5, linetype="dashed",color='red')+
geom_hline(yintercept = 343.5, size=.5, linetype="dashed",color='darkblue')


```


```{r,message=FALSE, include= FALSE, echo=FALSE}
ggplotly(plt)
```


