---
title: "Unidad 2 Tema 2.3"
author: "José Luis Manzanares Rivera"
date: '2022-11-01T21:13:15-05:00'
---

```{r, message=FALSE,warning=FALSE,include=FALSE}
library(tidyverse)
library(datagovindia)
library(plotly)
library(gapminder)
```


## Distribuciones de probabilidad 


#### Objetivos

+ Estudiar las distribuciones de probabilidad.

---------------

#### Distribución Binomial.

¿A qué nos referimos con una disrtibución Binomial? 

¿Qué circunstancias dan lugar a una distribución binomial? 



1. Tenemos un determinado número **n** de observaciones.

2. Las **n** observaciones son todas **independientes**. 

Es decir, saber el resultado de una observación **no te indica nada sobre las restantes observaciones**.

3. Cada observación tiene **dos** resultados posibles, que por conveniencia llamaremos **“éxito”** y **“fracaso”.**

4. La probabilidad de éxito, llámada **p**, es **igual** en todas las observaciones.


**Ejemplo: 1** 

Lanzar una moneda **n** veces es un ejemplo de **situación binomial**. 

Cada lanzamiento puede dar águila  o sol.

Conocer el resultado de un lanzamiento no nos dice nada sobre el resultado de los otros lanzamientos, por tanto, los **n** lanzamientos
son **independientes.** 

Si llamamos **“éxito”** a los sol, la probabilidad **p** de obtener
**sol** se mantiene constante si no cambiamos de moneda. 

El recuento del número
de **soles** es una **variable aleatoria X**. La distribución de **X** se llama **distribución
binomial.**


##### Definición: 

La distribución del recuento **X** de **éxitos** en una **situación binomial** es la
distribución binomial con parámetros **n** y **p**. 

Donde el parámetro **n** denota el número
de observaciones. 

Donde el parametro **p** indica la probabilidad de éxito de cualquier observación.

Y los valores de **X**  estan definidos por **números enteros positivos** en el intetvalo [**0 a n)**.


Es muy importante que los eventos sean **INDEPENDIENTES** para que una situación pueda definirse como binomial, no solo debemos verificar que se tengan **dos posibles** resultados.


**Ejemplo 2**

Observe que la siguiente situación **no cumple** con **el criterio** de independencia y por lo tanto no puede considerarse **situación binomial**.


Selecciona 10 cartas de una baraja de póquer y cuenta el número X de cartas rojas. 


Note que una baraja tiene dos cartas de **dos colores: Rojo y Negro.**

Tenemos 10 observaciones y cada una de ellas puede ser una carta roja o una carta negra. 

Definimos Un **“éxito”** como una carta **roja.** Note que tenomos dos posibles resultados, pero se viola el criterio de independencia, las observaciones **no son independientes.**

Ya que,  si **la primera carta es negra**, la segunda carta tiene más probabilidades de ser roja, ya que quedan más cartas rojas que negras en la baraja.


**Ejemplo 3**

Observas el sexo de los próximos 20 bebés nacidos en un hospital; **X** es el número de niñas.

+ Tenemos dos posibles resultados:  OK
+ Tenemos definida el evento éxito: OK
+ Los eventos son independientes:   OK


En este caso tenemos una situación binimial.

Para calcular la **probabilidad** de que una variable
aleatoria binomial tome un valor determinado es necsario: 

Determinar el número de maneras de combinar  **k** éxitos de entre **n** observaciones. Este número de combinaciones posibles se expresa por el  denominado **coeficiente binomial** que cuya notación se presenta a continuación.


##### COEFICIENTE BINOMIAL

El número de maneras de combinar **k** éxitos entre **n** observaciones viene dado por el **coeficiente binomial**


$$\binom{n}{k} = \frac{n!}{k!(n-k)!}$$

para  $k=0,1,2,...,n$

**Note** que  estamos usando la notación factorial. 

Recuerde que para estimar el **factorial** de cualquier número entero positivo **n**, es necesario estimar el producto de los elmentos secuencalente inferiores:

n! = n × (n − 1) × (n − 2) ×···× 3 × 2 × 1


**Por ejemoplo**

+ 4! = 4x3x2x1=24.

+ 3! =3x2x1=6

+ 6!= 6x5x4x3x2x1=720

O simplemente usando la función     `factorial en R` 
+ Por definción el caso particular de  0!=1.


##### PROBABILIDAD BINOMIAL


Si **X** tiene una **distribución binomial** con **n** observaciones y con una probabilidad **p** de éxito en cada observación k  = 0, 1, 2, . . . , n.  de **x**, Entonces.  


$$P(X=k)=\binom{n}{k}p^{k}(1-p)^{n-k}$$



**Ejemplo** Si en una situación binomial (con dos resultados independientes) se sabe que la probabilidad de ocurrencia del evento denominado éxito **p=0.25** ¿Cuál será la probabilidad binomial de  obtener **al menos 2 éxitos entre 5 posibles elementos**.

Considerando la notación  vista hasta el momento en este caso  k=2 , n=5.




En primera instancia podemos estimar el coeficiente binomial para el número de existos hasta k=2. Acorde con la situación descrita en la pregunta en donde buscamos la probabilidad de ocurrencia de al menos dos exitos.

Asi la probabilidad que buscamos queda definida por: 

$$P(X=2)=\binom{5}{2}p^{2}(1-p)^{5-2}+\binom{5}{1}p^{1}(1-p)^{5-1}+\binom{5}{0}p^{0}(1-p)^{5-0}$$

$$P(X\leq2)=\binom{5}{2}0.25^{2}(0.75)^{5-2}+\binom{5}{1}0.25^{1}(0.75)^{5-1}+\binom{5}{0}0.25^{0}(0.75)^{5-0}$$
library(binom)
binom(5, 2)
```{r}
library(VeryLargeIntegers)

binom(5, 2)
binom(5, 1)

### El coef binomial para n,k : 5,0=1 se sigue de la definición del coeficiente binomial.
```

$$\binom{5}{0} = \frac{n!}{k!(n-k)!}=\frac{120}{1(5)}!=\frac{120}{120}=1$$

Entonces, $$\binom{5}{2}=$$

$$\binom{5}{2}=10$$
$$\binom{5}{1}=5$$
$$\binom{5}{0}=1$$
$$P(X\leq2)=10(0.25)^{2}(0.75)^{5-2}+5(0.25)^{1}(0.75)^{5-1}+1(0.25)^{0}(0.75)^{5-0}$$
$$P(X\leq2)=10(0.25)^{2}(0.75)^{3}+5(0.25)^{1}(0.75)^{4}+1(0.25)^{0}(0.75)^{5}$$
La probabilidad binomial de obtener "como máximo 2 éxitos" entre los 5 posibles elementos será $89.64\%$



###### Aplicación usando software.

Utilizaremos la funciión  `dbinom`  cuyos parámetros son: **(n,k,p)**

Recuerde que es importante observar la proposición que describe la probabilidad. Por ejemplo en el caso anterior se busca "como máximo 2 exitos" así que $k\leq2$  por lo tanto la probabilidad que buscamos es $p(X\leq{2})=P(X=2)+P(X=1)+P(X=0)$ 

**Note** en este caso **la suma de las probabilidades** concretas de cada combinación.


```{r}

##  dbinom(n,k,p) 

 dbinom(2,5,0.25) + dbinom(1,5,0.25) + dbinom(0,5,0.25) 

```



$$\binom{n}{k} = \frac{n!}{k!(n-k)!}$$

$$\binom{5}{2} = \frac{5!}{2!(5-2)!}$$
$$\binom{5}{2} =\frac{5!}{2!(3)!}=\frac{120}{12}=10$$

En seguida aplicamos la notación de la **probabilidad binomial** y la regla de suma: 




---------------------


![](/img/reglas_Prob.jpg)

En particular note que la **regla 4** refiere la probabilidad de dos eventos que **no pueden ocurrir juntos**, estos eventos se denominan **disjuntos**

**Definición**  Son eventos disjuntos aquellos que no pueden ocurrir al mismo tiempo.

Los eventos **A** y **B** son disjuntos si su intersección es cero. 
$A\cap B=0$






 **Ejercicios**
 
 Repaso tema Distribución normal. 

![](/img/mediaymediana2.jpg)
![](/img/mediaymediana.jpg)

![](/img/ejerciciodensidad.jpg)




### Distribuciones contínuas.

Muy a menudo, encontramos datos que no se limitan a cifras enteras, por ejemplo el tipo de cambio **Peso/USD**, los registros de temperatura, en estos casos necesitamos una función contínua para describir su distribución.


### KDF Función de densidad Kernel

Permite la representación de la districuión considerando una aproximación contínua,no discreta como es el caso del histograma. 


![](/img/den_hist.jpg)



Note que el área bajo la curva de la **función de densidad** representa la proporción de observaciones en un intervalo concreto. Siendo el **area total igual a 1**. 

En análogía a la información que aporta el **histograma** que es una representación  **discreta** como ya hemos estudiado   



##### Ejemplo 1. 

Cálculo función de densidad, representación de medidas de tendencia central  y distribución esperanza de vida países en Africa vs. los paises de Asia.


```{r, echo= FALSE, fig.height = 5, fig.width = 6.5}


library(gapminder)

base<-gapminder

datos<-gapminder%>%filter(continent=="Asia" | continent=="Africa")

groups<-datos%>%group_by(continent)%>%
  summarize(le=mean(lifeExp))


p<-ggplot(datos, aes(x=lifeExp, fill=continent))+
geom_density(alpha=.2)+  
labs(color="Continente")+
xlab("GDPpercap")+
ylab("Density  f(y)")+
theme_classic()+
geom_vline(xintercept= 49, linetype="dotted", color="red")+
geom_vline(xintercept= 60, linetype="dotted", color="blue")+
annotate("text", x=49, y=.005, size=2,label="Esperanza de vida (años)")+ theme(legend.title=element_blank())

ggplotly(p)

```



```{r, include=FALSE}

## Source: https://www.gob.mx/salud/documentos/coronavirus-covid-19-comunicado-tecnico-diario-238449

agedf<-readRDS("agedf.rds")


dp<-ggplot(agedf, aes(x=edad, fill=sex))+
geom_density(alpha=.2)+  
labs(color="Sex")+
xlab("Patient age  (years)")+
ylab("Density  f(y)")+
theme_classic()+
scale_fill_discrete(labels=c("Female", "Male"))+
geom_vline(xintercept =mean(agedf$edad), linetype="dotted", color="red")+
annotate("text", x=32, y=.005, size=2,label="Mean patient age")+ theme(legend.title=element_blank())

ggplotly(dp)
```

```{r, include= FALSE}

##**Ejemplo 2**  Distribución de edades para defunción por covid en México. Funciones estudiadas (Verbos tidyverse aplicados): Filter, select, mutate, summarise. ggplot 


open<-readRDS("open.rds")

def<-filter(open, resultado==1)%>%
  filter(fecha_def!="9999-99-99")%>%
  select(sexo, edad)
def$sexo[def$sexo == "1"] <- "Female"
def$sexo[def$sexo == "2"] <- "Male"  
def<-mutate(def,sexo=as.factor(sexo))

fmean<-filter(def, sexo=="Female")%>%
  mutate(varmean=mean(edad))%>%
   summarise(mean=mean(varmean))

mmean<-filter(def, sexo=="Male")%>%
  mutate(varmean=mean(edad))%>%
   summarise(varmean=mean(varmean))

  
p<-ggplot(def, aes(x=edad, fill=sexo))+
geom_density(alpha=.2)+  
labs(color="Sex")+
xlab("Person age  (years)")+
ylab("Density  f(y)")+
theme_classic()+
scale_fill_manual(values = c("brown","blue4"))+
geom_vline(xintercept = fmean$mean, linetype="dotted", color="purple")+
geom_vline(xintercept = mmean$varmean, linetype="dotted", color="blue")+
annotate("text", x=44, y=.005, size=3,label="Mean person age")+ theme(legend.title=element_blank())


ggplotly(p)
```





```{r,  fig.height = 8, fig.width = 12,  message=FALSE, warning=FALSE, include=FALSE}

####  Caso Aguascalientes

#**Ejemplo  3** Función de densidad para dos categorias. Funciones estudiadas: group_by, rename, left_join, filter, select, mutate, summarise. ggplot 



sdensity<-readRDS("density.rds")%>%
  mutate(s=as.factor(s))%>%
  filter(ENT_RESID!=33& ENT_RESID!=34& ENT_RESID!=35& ENT_RESID!=99)%>%
  group_by(ENT_RESID)

cat_e<-read.csv("cat_entidad.csv")%>%
select(-X)%>%
rename(ent_res=X.U.FEFF.EDO)%>%
mutate(ent_res=sprintf("%02d",ent_res))%>%
mutate(ENT_RESID=as.factor(ent_res))%>%
select(-ent_res)

sdensity<-left_join(sdensity,cat_e)



ags<-filter(sdensity,ENT_RESID=="01")%>%
  mutate(s=as.factor(s))


aplt<-ggplot(ags, aes(x=age,linetype=s, color=s))+
geom_line(stat="density")+
labs(linetype="Causa")+
xlab("Edad de la persona (Años)")+
ylab("Densidad f(y)")+
annotate("segment", x=29, xend=13, y=0.011, yend=0.011,  size=.3, arrow=arrow(length=unit(.2,"cm")))+
annotate("text", x=23, y=0.013, label="Alta incidencia")+
annotate("text", x=21, y=0.009, label="13<Edad<29")+
annotate("rect", xmin=13, xmax=29, ymin=0, ymax=0.03, alpha=.1,fill="black")+
scale_linetype(labels=c("Otras causas","Suicidio"))+
theme_classic()+
scale_color_manual(values = c("mediumturquoise","magenta1"))+
theme(legend.position="none")


aplt

```




```{r,  fig.height = 8, fig.width = 12, message=FALSE, warning=FALSE, include=FALSE}

#**Ejemplo 4** Función de densidad multiples bases de datos. (32 estados de México). Herramienta de análisis: stat=density 

#Funciones estudiadas: **facet_wrap**
mxplt<-ggplot(sdensity, aes(x=age,linetype=s, color=s))+
geom_line(stat="density")+
labs(linetype="Causa")+
xlab("Edad de la persona (Años)")+
ylab("Densidad f(y)")+
facet_wrap(~DESCRIP, nrow=6)+
scale_linetype(labels=c("Otras causas","Suicidio"))+
  theme_classic()+
scale_color_manual(values = c("mediumturquoise","magenta1"))+
  theme(legend.position="none")

mxplt
```



**Nota sobre ventajas de las KDF: **

Nos permiten distinguir rapidamente características como los atributos de tendencia central, la presencia de  bimodalidad,  sesgo), también facilitan la comparación rápida entre diferentes conjuntos de datos.

Por ejemplo vemos en la figura siguiente que la **media** de un conjunto de datos con **sesgo positivo** se ubica **a la derecha** de la mediana.

**IMPORTANTE ** En este caso **la mediana** será la medida de tendencia central **preferible** o que describe con mayor precisión la ubicación del **dato central**, por que divide la distribución de la curva en dos areas iguales. 

![](/img/asimetria_positiva.jpg)

**Una propiedad importante:**

*"El área por debajo de la curva, y entre cualquier intervalo de valores, es la proporción de todas las observaciones que están situadas en dicho intervalo."*

+ Note que el area por debajo de la KDF, siempre es igual a 1. 

En otras palabras, si sumamos la proporción que integra la distribución total, tenemos el 100% 


###  Función de distribución de probabilidad PDF.

La curva que describe la probabilidad para cada valor, (la distribución de probabilidad),  es una **función contínua** y se denomina función de **densidad de probabilidad.** $p(x)=$**(PDF).** 


La **PDF** (función de densidad de una variable **aleatoria continua**), es una función que describe la probabilidad de que una variable aleatoria **X** tome un valor particular **x**  

**X** Variable aleatoria ej. ingreso
**x:** valor particular de la variable aleatoria. ej. $60 000.

La pregunta es ¿cuál es la probabilidad de que la variable **X** tome un valor particular **x**

La **PDF** tiene las propiedades: 


> $${p(x)}\geq0, 	\forall x \in R$$
> $$\int_{-\infty}^{\infty}     p{(x)}dx=1$$

![](/img/PDF_probability.jpg)

La integral de p(x) en el rango [a,b] representa la probabilidad de encontrar el valor **x** en ese **intervalo**.  El area bajo la curva, determina el valor de esa probabilidad en el intervalo particular. A esta area la denominamos función de densidad acumulada **CDF** 


#### Aplicación.

La **CDF** es útil para en la estimación de los **percentiles.**

La manera más simple de determinar los percentiles es mediante la estimación de la **función de densidad acumulada** **CDF** (por sus siglas en inglés). 
$$CDF(x)=\int_{-\infty}^x PDF(x)dx$$

#### ECDF Función de densidad acumnulativa empírica.

Conocer la frecuencia es importante pero muy a menudo necesitamos conocer que proporción de nuestras observaciones se ubica por debajo de un cierto umbral.

Para este propósito es muy útil estimar la frecuencia acumulada. 

Una representación contínua de este concepto es mediante la función empírica de **densidad  acumulada** 


Una nota sobre la apliación de la **CDF** en la obtención de los **Percentiles** 

Los percentiles permiten determinar el valor por debajo del cual, ocurre un determinado porcentaje de los datos.

La  función de distribución acumulada**CDF** es la integral de la **función de densidad de probabilidad (PDF)**. 

Define la probabilidad de observar un valor **x** en un rango determinado **[a,b].** 
Formalmente 

![](/img/cdf.jpg)


Revisemos ahora en la práctica como podemos estimar la **función de densidad**  usando **Python.**

**"Sesión_2_Tendencia central.ipynb"**

Nota sobre implementación en **Python**. Esta  nos permite observar el porcentaje acumulado de datos en el eje de las ordenadas al orígen y los valores observados en el eje de las absisas.

La pregunta básica que podemos responder estimando la **CDF**, es ¿qué porcentaje de los datos se ubica por debajo de cualquier umbral deseado?


## Distribuciones discretas.


Un ejemplo **clásico** simple de una distribución de **probabilidad discreta** es el lanzamiento de un dado. 

Para cada uno de los lados desde $i=1.....6$ la probabilidad de que un lanzamiento del dado tenga la cara $i$ es $$P_{i}=\frac{1}{6}$$  Con $i=1....6$


Las propiedades de la distribución discreta de probabilidad son : 
+ $$0\leq{P_{i}}\leq{1}, 	\forall i \in N$$


+ $$\sum_{i=1}^{n} P_{i}=1$$




## Distribuciones de probabilidad.

#### Distribuciones discretas


Dos de las distribuciones discretas más comunes son: la distribución **Binomial** y **Poisson.**

La diferencia básica entre ambas es que la **Binomial** tiene un límite superior definido. 

##### Distribución Binomial. 

Considere la ejecución de una serie de experimentos. 

La distribución binomial aplica si se cumplen los siguientes supuestos: 

+ Los ensayos son independientes. 

+ Cada ensayo tiene la misma probabilidad de exito. 

+ El número de ensayos es conocido 

+ Se define un parámetro denominado **éxitos** "x", como el número de éxitos dentro de los **"n"** ensayos.

De esta forma la función de probabilidad binomial se define como: 

$$P(x)=\frac{n!}{x!(n-x)!}p^{x}(1-p)^{n-x} $$

La función nos permite estimar la probabilidad de que ocurra una cantidad determinada de éxitos.  P(x).  P (mayúscula).

Note que  **p** (mínuscula) es la probabilidad de éxito de cada ensayo y su inverso es la probabilidad de fracaso. 





La **distribución de Bernoulli**

Es una distribución dicotómica. 

Si {\displaystyle X}X es una variable aleatoria discreta que mide el "número de éxitos" y se realiza un único experimento con dos posibles resultados denominados éxito y fracaso, se dice que la variable aleatoria **X** se distribuye como una **Bernoulli** de parámetro **p**  con  $$0<p<1$$ y escribimos   $X\sim \operatorname {Bernoulli} (p)$.

Si  (exito=1 , fracaso =0) , Exito toma la prob. p y fracaso q=(1-p)


![](/img/bernoulli.jpg)


Esta distribución presenta **dos estados.**  Como ejemplo más simple, el lanzamiento de una moneda.
Ver ejemplo **Sesión 3.ipynb**

Otros ejemplos empíricos con situaciones en donde se presenta una distribución **Binomial**, incluyen todas aquellas situaciones con dos resultados posibles: Ej. Pasar o no el exámen, lanzar una moneda, que un candidato a la presidencia gane o pierda, etc., 


-------------------------

 






