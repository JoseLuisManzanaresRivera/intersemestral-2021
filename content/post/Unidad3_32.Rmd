---
title: "Unidad 3 Distribución t"
output: html_document
date: '2022-11-30'
categories: ["Prueba de hipótesis para medias"]
tags: ["Distribución t"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Objetivos.

Estudiar los métodos estadísticos para hacer inferencia sobre la media de una población y para comparar las medias de dos
poblaciones.

Estos métodos incluyen las **pruebas basadas en la distribución t y los intervalos de confianza** para valorar la diferencia estadística entre medias  en circunstancias donde tenemos muestras pequeñas. Concretamente nos interesa el estudio y aplicación de la **distribución t** para el contraste de hipótesis entre la media de dos poblaciones. 

## Metas de aprendizaje.

+ El alumno será capaz de construir  intervalos de confianza y aplicar  las pruebas de significación para la media de una población y para la comparación de las medias de dos poblaciones.


Uno de los problemas que encontramos en la práctica con la utilización del estadístico estandarizado **z** para realizar inferencia es que **no conocemos el parámetro poblacional $\sigma$** desviación estándar poblacional. 


**William Gosset**, un destacado pionero en la construcción del campo que hoy conocemos como estadística, se ocupó de este tema y desarrolló una distribución para el estadístico $$\frac{\bar{x}-\mu}{s}$$
 
Ya que observó que no era suficiente substituir $\sigma$ por **s** y asumir normalidad de la distribución resultante, ya que los resultados no eran suficientemente precisos. 

Es gracias a **William Gosset**, quien desarrolló una **distribución de números críticos**  que comúnmente denominados **distribución t**[^1]   (adicional a la distribución **Z**  ya vista) que este problema se puede atender. Este será el tema de nuestra sesión de hoy.   



Material bibliografico de consulta para la sesión de hoy disponible en [Libro de texto](https://drive.google.com/file/d/1ezHlHeEPXBDIf2glXMsyZ0KzGsR8pM27/view?usp=sharing) Ver paginas 481-562.



## Definiciones y conceptualización


Los intervalos de confianza y las pruebas de significación para la media $\mu$ de una población normal se basan en la media muestral $\bar{x}$. 

La media de la distribución de $\bar{x}$ es $\mu$. Es decir, $\bar{x}$ es un **estimador insesgado** de la $\mu$ desconocida.


La dispersión de $\bar{x}$ depende del tamaño de la muestra y de la desviación estándar poblacional $\sigma$.


**Recordemos** de la sesión previa que haciamos el supesto poco realista de que conociamos $\sigma$. Pero en la práctica  $\sigma$ es desconocida.  Así que es necesario estimar este parámetro poblacional, lo cual es posible con base en los siguientes supuestos. 


#### Supuestos. 


+  Nuestros datos proceden de una **muestra aleatoria simple** de tamaño **n** de una población. 

+ Tanto $\mu$ como $\sigma$ son parámetros desconocidos.

+ Las observaciones proceden de una población que tiene una **distribución normal** con media $\mu$ y desviación estándar $\sigma$. 

En la práctica, si la muestra no es muy pequeña,  es suficiente con que la **población sea simétrica** y que no tenga dos modas (bi modal). 


### Definición: 

##### Error estándar de la media muestral. 

$$\frac{s}{\sqrt(n)}$$
**Importante**, note  que no conocemos  $\sigma$, por lo que utilizamos la desviación estándar muestral **s** para estimar el **error estándar** de la media muestral  $\bar{x}$


### Distribución t 


$$t=\frac{\bar{x}-\mu}{\frac{s}{\sqrt(n)}}$$

Con n-1 **grados de libertad**


**Note:**

**La distribución muestral t** no tiene una distribución normal.  

Existe una **distribución t** distinta para cada tamaño de muestra.


Note el contraste con el estadístico $$z=\frac{\bar{x}-\mu}{\frac{\sigma}{\sqrt(n)}}$$

Este tiene una **distribución normal** caracterizada con los parámetros media y desviación estándar **N(0,1)**


La interpretación del **estadístico t** es la misma que la correspondiente z. **Es decir, nos dice la distancia de la media muestral respecto de la poblacional en términos de desviaciones estándar.**


Concretamos una **distribución t** determinada, dando sus **grados de libertad.** que se obtienen a partir de la desviación estándar muestral **s** en el denominador de t.  

Usaremos la letra **k** para para definir el número de grados de libertad. 

La siguiente figura muestra el contraste entre la **distribución t** y la normal estandarizada  **(z)** para diferentes **k**

![](/img/t.jpg)

Note que **las distribuciones t** tienen más probabilidad en los extremos que la normal estandarizada. 

Notemos además los siguientes rasgos destacados. 

+ Simetría

+ Unimodal

+ Forma Gaussiana (campaña)

+ Centradas en 0 

+ s en **t dist** > s en **z dist.** lo que implica una mayor probabilidad en los extremos para  las **t dist** 

+ A medida que el **tamaño de muestra es mayor** y el número de **grados de libertad**[^2] es mayor,  la **t dist** se parece más a la **z dist  N(0,1)**.

*¿Bajo qué circunstancias podemos utilizar la distribución t para hacer inferencia estadística?*

#### Criterios referentes al tamaño de muestra para la utilización de los procedimientos t.

+ **Muestras grandes.** Los procedimientos t se pueden utilizar incluso
para distribuciones muy asimétricas cuando la **muestra sea grande,** aproximadamente cuando **$n\geq 40$**.


La principal razón para este punto es el **teorema del límite central.** El estadístico **t** utiliza la
media muestral $\bar{x}$, la cual es más normal a medida que aumenta el tamaño de la muestra, incluso cuando la población no tiene una distribución normal.

+ **Tamaño de muestra menor que 15.** Utiliza los procedimientos t
si los datos son aproximadamente normales. Si los datos no
son claramente normales o si existen observaciones atípicas,
**no utilices los procedimientos t.**

La recomendación es que siempre que tengas muestras pequeñas, antes de utilizar los procedimientos **t**, dibuja un gráfico para detectar asimetrías o la presencia de observaciones atípicas.

+ **Tamaño de la muestra mayor o igual a 15**. Los procedimientos t se
pueden utilizar **a no ser que existan observaciones atípicas o que la distribución sea muy asimétrica.**

*Las observaciones atípicas sugieren que los datos no constituyen una muestra de una población normal.*

+ Excepto en el caso de muestras pequeñas, el supuesto de que
los datos sean una **muestra aleatoria simple** de la población de
interés es más importante que el supuesto de que la distribución
de la población sea normal.



El siguiente diagrama muestra el esquema conceptual para la utilización práctica de las pruebas basadas en la **distribución t** para contraste de hipótesis que buscan valorar la diferencia entre medias. 

![](/img/esquema.jpg)

#### I Procedimientos t para una muestra.

1.- Obtén una muestra aleatoria simple de tamaño **n** de una población de media $\mu$ desconocida.


**Intervalo de confianza de nivel C para $\mu$**

$$\bar{x}\pm t* \frac{s}{\sqrt(n)}$$
donde $t^{∗}$ es el valor crítico superior (1−C)/2 de la distribución t(n − 1)

**Valor de contraste para** $H_0: \mu=\mu_0$

$$t=\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt(n)}}$$

![](/img/contrastet.jpg)

##### Ejemplo 1

[Descarga de Datos dar click aquí ](https://drive.google.com/file/d/1yRZIMFGmA5YLenNr2XDcfbsG8YwpeDcr/view?usp=sharing)


|id	|  NCF/100ml|
|---|---|
|1	|248|
|2	|37|
|3	|146|
|4	|19|
|5	|66|
|6	|236|
|7	|164|
|8	|30|
|9	|13|
|10	|144|
|11	|242|
|12|	20|


Para investigar la calidad del agua, a fines de julio de 2021, el Departamento de Salud de la comisión fronteriza de Tijuana recolectó muestras de agua de 12 playas entre Rosarito y  San Antonio del Mar en el Municipio de Tijuana.

Esas muestras se analizaron para coliformes fecales, que son bacterias E. coli que se encuentran en las heces humanas y animales. Un nivel inseguro de coliformes fecales significa que hay una mayor probabilidad de que haya bacterias que causan enfermedades y un mayor riesgo de que un nadador se enferme si accidentalmente ingiere parte del agua. Un sitio web considera que **no es seguro** si una muestra de 100 mililitros de agua contiene más de **88 bacterias coliformes.**


Los niveles de coliformes fecales pueden cambiar a medida que cambian el clima y otras condiciones. Estas playas se habían considerado seguras a principios del verano de 2021, y la razón por la que se recopilaron datos fue para determinar si esto seguía siendo cierto. 

Por lo tanto, estamos buscando evidencia de que las condiciones pasadas a lo largo de este tramo de playas se hayan deteriorado. 

Hacemos la pregunta en términos del nivel medio de coliformes fecales $\mu$ para todas estas playas. La hipótesis nula es "el nivel es seguro" y la hipótesis alternativa es "el nivel no es seguro":

$$H_0: \mu=88$$

$$H_a: \mu>88$$

```{r, warning=FALSE,message=FALSE}
# Solución

library(tidyverse)

## Cargamos la base de datos.

t1<-read.csv("ejemplot1.csv")


glimpse(t1)

# Verificamos supuestos considerando criterios de tamaño de muestra y normalidad (especialmente simetría).

# (a) Tamaño de muestra menor a 15.  n<15. !!!!

#(c) Normalidad:  COn Shapiro.

shapiro.test(t1$NCF.100ml)


# => p-value = 0.03 !!!!  Al nivel de significancia del 0.05 rechazamos H0. Normalidad. Concluimos que estos datos no provienen de una distribución normal.

## Realizaremos el procedimiento con fines didácticos únicamente, pero los resultados no serán vÁlidos.

xbar<-mean(t1$NCF.100ml)
mu<-88
n<-12

s<-sd(t1$NCF.100ml)

error<-s/sqrt(n)


t<-(xbar-mu)/error


df<-n-1

## uSAMOS TABLAS para t= 0.94 con gl=11 en página 789- Esta es entre 0.20 y 0.15 

## uSAMOS LA FUNCIÓN pt PARA ESTIMAR  EL VALOR P PARA EL VALOR CRíTICO T.


t=1.85
df<-15

pt(t, df, lower.tail = FALSE)

# lOWER TAIL FALSE IMPLICA QUE UPPER TAIL TRUE, O SEA P DEL EXTREMO DERECHO DE LA DIST.

#### O MEJOR AUN, REALIZAMOS LA  ESTIMACIÓN DIRECTA. CON LA función t.test.

t.test(t1$NCF.100ml, mu = 88,   paired = FALSE,
       alternative = "greater")

## p-value = 0.1813  >  p valor crítico alpha la 0.05. Por lo tanto concluimos que los niveles de bacterias coliformes en promedio no superan los 88 por 100 mililitros. No podemos rechazar HO. Concluimos que las playas son seguras, dados los niveles observados de bacterias coliformes por las muestras.

```
![](/img/et1.jpg)



```{r}

## Paso 1 Cargamos los datos  

Ejemplo1_t<-read.csv("t.csv")

# Paso 2. Revisar supuestos para aplicar la prueba. 

# (a) Tenemos una MAS,  en pares con mediciones para los mismos individuos. 

# (b) ¿Tenemos una muestra de tamaño adecuado, simétrica, normal? El tamaño es n>15. 

##  usando un diagrama de tallos (stem and leaf) podemos comprobar que hay simetría en la distribución de las diferencias. Este es un metodo para apreciar mediante tabulación la distribución de los datos. Es un método alternativo a los histrogramas, pero en este caso la diferencia principal es que podemos ver los datos individuales lo que no ocurre en los histogramas por que tenemos lo datos agrupados en rangos.   Esto es suficiente pero además podemos revisar la normalidad con la prueba Shapiro que (esta tiene como H0 Normalidad).

shapiro.test(Ejemplo1_t$diff) # => p-value = 0.9905


stem(Ejemplo1_t$diff)



t.test(Ejemplo1_t$A, Ejemplo1_t$B,  paired = TRUE, alternative = "greater")

```




##### Ejercicio 16

El estadístico **t** de una muestra para contrastar $$H_0: \mu=0$$ $$H_a: \mu > 0$$ para una muestra n= 16  es  $t=1.85$


(a) ¿Cuántos grados de libertad tiene este estadístico? 

(b) ¿Cuáles son las probabilidades p de la cola de la derecha de estos dos valores?

(c) ¿Entre qué dos valores se encuentra el valor P de la prueba?

(d) Utiliza software y determina la probabilidad exacta en el extremo derecho de la distribución  para t = 1.85 ¿Es significativo el valor t = 1.85 a un nivel del $5\%$? ¿Es significativo a un nivel del $1\%$?



```{r,include=FALSE}

# Solución

# (a) El estadístico  t tiene n-1 grados , es decir gl=15

# (b)    t (15) = 1.753 P(0.05), 2.131 P(0.025). 

# (c)  Entre el 0.025 y 0.05,  o bien  entre el 2.5% y 5%

# (d)  Es significativo al 5% pero no al 1%

#   p VALOR= 0.032 
1-pnorm(1.85)

```


#### II Procedimientos t para diseños por pares.


Para comparar los elementos en un diseño por pares,
aplica los procedimientos t de una muestra a las diferencias observadas.


El parámetro $\mu$ en un procedimiento **t** de un diseño por pares es la media de las diferencias entre  los elementos de cada par en toda la población.





#### Ejemplo 2

Los siguientes datos indican el tiempo promedio en segundos que 21 sujetos tardan en resolver un problema de estadistica. El experimento  se basa en la realización de los cálculos necesarios para resolver el problema usando: A) calculadora y B) el programa de software excel.  El orden de la realización del problema es aleatorio. 

Las hipótesis que se desean probar son. Si el uso de excel mejora el desempeño de los participantes medido por el tiempo promedio de solución del probelma. En otras palabras se busca determinar si el tiempo promedio usando calculadora **supera** al tiempo logrando en el escenario B. Lo que implicaría que el uso de excel no tiene efecto. 


Formalmente, tenemos una prueba de un extremo para: $$H_0: \mu=0$$ Lo queimplica que no hay efecto. $$H_0: \mu>0$$ Implicando que Si hay efecto. 

[Datos](https://drive.google.com/file/d/1R0dVimjsLY4xG6Eozm8vWfZ62kyUwPDU/view?usp=sharing)



|A	   |B	      |Diferencia  | 
|:-----:|:-----:|:------------:|
| 30.6	| 37.97 | -7.37   |
| 48.43 | 51.57 | -3.14   |
|60.77  |	56.67 |	4.1    |
|36.07|	40.47|	-4.4|
|68.47|	49	|19.47|
|32.43|	43.23|	-10.8|
|43.7	|44.57|	-0.87|
|37.1	|28.4	|8.7|
|31.17|	28.23|	2.94|
|51.23|	68.47|	-17.24|
|65.4	|51.1	|14.3|
|58.93|	83.5|	-24.57|
|54.47|	38.3|	16.17|
|43.53|	51.37|	-7.84|
|37.93|	29.33|	8.6|
|43.5	|54.27|	-10.77|
|87.7	|62.73|	24.97|
|53.53|	58|	-4.47|
|64.3	|52.4|	11.9|
|47.37|	53.63|	-6.26|
|53.67|	47|	6.67|
|-----|----|----|


```{r}


## Paso 1 Cargamos los datos  

Ejemplo1_t<-read.csv("t.csv")

# Paso 2. Revisar supuestos para aplicar la prueba. 

# (a) Tenemos una MAS,  en pares con mediciones para los mismos individuos. 

# (b) ¿Tenemos una muestra de tamaño adecuado, simétrica, normal? El tamaño es n>15. 

##  usando un diagrama de tallos (stem and leaf) podemos comprobar que hay simetría en la distribución de las diferencias. Este es un metodo para apreciar mediante tabulación la distribución de los datos. Es un método alternativo a los histrogramas, pero en este caso la diferencia principal es que podemos ver los datos individuales lo que no ocurre en los histogramas por que tenemos lo datos agrupados en rangos.   Esto es suficiente pero además podemos revisar la normalidad con la prueba Shapiro que (esta tiene como H0 Normalidad).

shapiro.test(Ejemplo1_t$diff) # => p-value = 0.9905
## No rechazamos H0, los datos provienen de una distribución normal. 



stem(Ejemplo1_t$diff)

## Aplicación de la prueba, con base en las hipótesis previamente definidas.

t.test(Ejemplo1_t$A, Ejemplo1_t$B,  paired = TRUE,
       alternative = "greater")
## Note que tenemos la posibilidad de controlar si la prueba es de una o dos colar y en este caso si es para una media mayor o menor que la especificada  por la hipótesis nula.

# Conclusión, no podemos rechazar H0, No hay evidencia estadísticamente significativa que indique que la diferencia entre medias sea mayor a cero.  La media de las diferencias es 0.9566667, con valor P 0.36> valor critico al 0.05. Lo cual es una diferencia infima si lo contrastamos con  el tiempo medio que la solución del problema representa que es 50.01 segundos. 

mean(Ejemplo1_t$A)
```


##### Ejercicio 17.


La  Procuraduria Federal del consumidor  (PROFECO) ha diseñado una serie de estándares para constrastar el peso expresado por los equiquetados en productos cárnicos ofrecidos en supermercados y el peso real. 

Como parte del procedimiento de validación de los estandares, realiza un experimento que consiste en la inspección en 12 muestras, en las que se obtienen los siguientes resultados. 

| Real | Etiquetado |  Diferencia |
|:-----:|:-----:|:------------:|
|	1.67	|	1.85	|	-0.18	|
|	1.14	|	1.21	|	-0.07	|
|	1.48	|	1.56	|	-0.08	|
|	1.84	|	1.98	|	-0.14	|
|	0.84	|	1.07	|	-0.23	|
|	1.39	|	1.55	|	-0.16	|
|	1	    |	1.02	|	-0.02	|
|	1.19	|	1.44	|	-0.25	|
|	1.17	|	1.33	|	-0.16	|
|	1.83	|	2.03	|	-0.2	|
|	1.59	|	1.73	|	-0.14	|
|	1.05	|	1.16	|	-0.11	|


(a) Realice un diagrama de tallos basado en la variable *diferencias* (stem and leaf plot) para analizar la distribución y detectar posibles sesgos.   Comente sobre la presencia de **outliers** que puedan advertir sobre la imposibilidad del uso de la prueba basada en el distribución t.

(b) Lleve a cabo una prueba t para derterminar si la media del equiquetado es mayor a la que se observa por las mediciones de inspección. Para los niveles de significación del $5\%$ y $1\%$

[Descargue los datos aquí. click click](https://drive.google.com/file/d/1Fbxzn1eISWFa0VRbeM3qG_OgL9reipb1/view?usp=sharing)

```{r,include=FALSE}

library(tidyverse)




pairs<-read.csv("pairs.csv")%>%
  mutate(dif=etiquetado-inspección)

glimpse(pairs)

# a) 

stem(pairs$dif)

# No se aprecian valores atípicos. no se tiene asímetria aparente. 

# b)  

xbar<-mean(pairs$dif)
s<-sd(pairs$dif)
s_muestral<-s/sqrt(n)
n<-12

# Calculando el t critico para tablas.

tcritico<-(xbar-0)/s_muestral 


# t = 7.47

t.test(pairs$etiquetado, pairs$inspección, paired = TRUE,
       alternative = "greater")



# pval=.0000006208 para t= 7.47

## La prueba es estadísticamente significativa al 1%,  podemos concluir al nivel de significación del 1% que  existe una diferencia estadisticamente significativa (no debida al azar), entre el equitetado y el peso registrado en el paquete. La media de la muestra etiquetado  es mayor que la media de los registros de la inspección . 
```


#### III Prueba entre dos o más poblaciones. 

¿Cuál es la diferencia entre un escenario que requiere una **prueba por pares** y uno dirigido a evaluar la diferencia entre dos muestras?

Este es el punto que abordarémos a continuación.

Si tenemos muestras independientes de dos o más poblaciones, tenemos un escenario propicio para la aplicación de la **prueba t** para dos o más muestras. 

A diferencia del caso de la prueba por pares, en la cual se tienen **elementos de una misma población**  en el caso de dos muestras **los indivduos a examinar provienen de dos poblaciones distintas**. 


La estructura de la evaluación es que se tienen muestras separadas de cada población.  La finalidad de estos contrastes es conocer si existe efecto o diferencia entre los dos grupos  dada la aplicación de un control. 


**En este caso las observaciones NO, se grupan por pares y las muestras pueden ser de distinto tamaño.**


Supuestos bajo los cuales se aplica el contraste para dos o mpas poblaciones. 



+ Tenemos **dos muestras aleatorias simples** de dos poblaciones distintas. Las muestras son **independientes**. Es decir, una muestra no tiene ninguna influencia sobre la otra. 
Medimos la misma variable en las dos muestra.

+ Las dos poblaciones tienen **distribuciones normales**. Las medias y las desviaciones estándar de las dos poblaciones son **desconocidas.**

La siguiente tabla indica la notación utilizada en el planteamiento de la prueba. 


![](/img/t2samples.jpg)
![](/img/n.jpg)

###### Definición del estadístico de contraste para dos muestras. 

 $$t=\frac{\bar{x_1}-\bar{x_2}}{SE}$$

Donde:

**Error de estimación (SE)** = $$\sqrt(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})$$

Su interpretación es igual a los valores estadarizados ya estudiados. Mide la distancia, de cero en términos de desviaciones estándar hacia el valor que toma la diferencia entre $\bar{x_1}$  y $\bar{X_2}$


En la práctica la determinación de los grados de libertad para el cálculo de **t** se basa en el valor menor entre $n_1 -1$ y $n_2 -1$


El estadístico t de contraste  y intervalo de confianza, quedan definidos por: 


$$t=\frac{\bar{x_1}-\bar{x_2}}{\sqrt(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})}$$



$$(\bar{x_1}-\bar{x_2})\pm t^*\sqrt(\frac{s_1}{n_1}\frac{s_2}{n_2})$$

##### Ejemplo.

La prueba Chapin (Chapin Social Insight Test) es una prueba psicológica diseñada con el objeto de determinar la precisión con la que un individuo capta la personalidad de los que le rodean. Los posibles resultados de la prueba van de 0 a 41.
Durante el desarrollo de la prueba Chapin, ésta se aplicó a diferentes grupos de personas. He aquí los resultados obtenidos con un grupo de estudiantes universitarios de Arte de ambos sexos.[^3]


![](/img/chapin.jpg)

¿Se puede afirmar que como media la capacidad de mujeres y de hombres
para captar la personalidad de las personas que les rodean es distinta?

¿Se puede afirmar que como media la capacidad de mujeres y de hombres
para captar la personalidad de las personas que les rodean es distinta?

**Paso 1: Hipótesis.** Se plantea el problema en términos de una hipótesis alternativa de dos colas. Las hipótesis son:

$$H_0: \mu_1=\mu_2$$
$$H_a: \mu_1\neq \mu_2$$

**Paso 2:** Estadístico de contraste. El estadístico t de dos muestras es

$$t=\frac{\bar{x_1}-\bar{x_2}}{\sqrt(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2})}$$

$$t=\frac{25.34-24.94}{\sqrt(\frac{5.05^2}{133}+\frac{5.44^2}{162})}$$
$$t=0.654$$
Note que en las tablas t no aparece el valor  de los grados de libertad, en este caso gl = 132, (n-1), por lo que consideramos el valor más cercano que es 100. 

En la definición de los **grados de libertad** note que seleccionamos  la **n** de menor tamaño acorde a la teoría descrita previemante.  


El **Valor p** es 0.25 dado que se trata de una prueba de **dos colas**, el valor p de crítico es P=.50=2P(t). Y este valor es mayor al valor P constraste al **90%** co alpha= 10%. 

**Conclusión:** No podem,os rechazar $H_0$ y Por lo tanto no observamos diferencia estadisticamente significativa entre la media para hombres y la de mujeres. 


**IMPORTANTE:** En este caso el tamaño de muestra grande hace que  la falta de normalidad de las muestras pierda importancia.  Note que estos resultados solo son validos para la población de estudio que se circunscribe a los estudiantes de un programa específico de una universidad. No se pueden generalizar para la pobalción de universitariso de un país!



##### Ejercicio 18.

Coeficientes de inteligencia de chicos y chicas. A continuación damos los resultados de una prueba de inteligencia de 31 chicas de secundaria de una determinada zona rural.[^4]

114 100 104 89 102 91 114 114 103 105
108 130 120 132 111 128 118 119 86 72
111 103 74 112 107 103 98 96 112 112 93

Los coeficientes de inteligencia de 47 chicos de secundaria de la misma zona
rural son

111 107 100 107 115 111 97 112 104 106 113
109 113 128 128 118 113 124 127 136 106 123
124 126 116 127 119 97 102 110 120 103 115
93 123 79 119 110 110 107 105 105 110 77
90 114 106

[Click aquí para obtener los datos](https://drive.google.com/file/d/105OehCk5S6K21PtOQQSmwd6EAwkojSGu/view?usp=sharing)


(a) Halla la media de los coeficientes de las chicas y también la de los chicos. En general, en pruebas estándar, los resultados de los chicos son ligeramente
superiores a los de las chicas. ¿Ocurre con nuestros datos?

(b) Dibuja diagramas de tallos o histogramas con los dos conjuntos de datos. Y aplica la prueba de normalidad e Shapiro para validar el supuesto de normalidad. 

Debido a que la distribución de los datos es razonablemente simétrica, sin la presencia de observaciones atípicas, se pueden utilizar los procedimientos t.


(c) Trata estos datos como si fueran una muestra aleatoria simple de los estudiantes de secundaria del municipo de Tijuana. **¿Existe evidencia con un nivel de significación estadística del 5% de que las medias de los coeficientes de inteligencia de chicas y chicos son distintas?**


```{r, include=FALSE}
library(tidyverse)

ej18<-read.csv("Chicas.csv")

## Exploraci[on de distribución para detectar posibles violaciones a supuestos de normalidad. 

histchicas<-ggplot(ej18,aes(Chicas))+
geom_histogram(colour="steelblue", fill="coral",alpha=0.4)

histchicos<-ggplot(ej18,aes(Chicos))+
geom_histogram(colour="steelblue", fill="brown",alpha=0.4)

## Diagrama de tallos para ambas muestras. 

stem(ej18$Chicas)
stem(ej18$Chicos)

## Aplicación de rpeuba para detectar normalidad con Shapiro test 

shapiro.test(ej18$Chicos)
## Resultado p-value = 0.1426, No rechazamos H0 de Normalidad.   Datos OK

shapiro.test(ej18$Chicas)
## Resultado p-value = 0.4673, No rechazamos H0 de Normalidad.   Datos OK

# Paso 1 Determinación de los estadísticos para estimación del valor t en calculadora. 

Chicas<-ej18%>%
select(Chicas)%>%
na.omit()

xbar1<-mean(Chicas$Chicas)
xbar2<-mean(ej18$Chicos)  
s1<-var(Chicas$Chicas)  
s2<-var(ej18$Chicos) 
n1<-31
n2<-47

## Paso 1   Estimar el t  crítico. 

t<-(xbar1-xbar2)/sqrt((s1/n1)+(s2/n2))
# t = -1.6439

# Usando R. 

t.test(ej18$Chicas,  ej18$Chicos, data = ej18, alternative = "two.sided")

## p-value = 0.1057

# Conclusión, No Rechazamos H0: mu1-mu2=0.  A los niveles de significación del 10%, 5%, y 1% .   No tenemos  evidencia estadisticamente significativa que indique que la diferencia entre resultados medios para Chicas y Chicos sea distinta de cero. 



```






[^2]: ¿Por qué usamos n-1 grados de libertad para el cálculo de la varianza? La razón es que la suma de las desviaciones $x_i -\bar{x}$ es siempre cero, la última desviación se puede hallar cuando se conocen las otras n − 1.

[^1]: La **t** *short for Student*, asociada a la publiación que el propio William realizó para difundir la distribución propuesta. Puede acceder al artículo original publicado en 1908 [en este enlace](http://seismo.berkeley.edu/~kirchner/eps_120/Odds_n_ends/Students_original_paper.pdf)

[^3]: H. G. Gough, The Chapin Social Insight Test, Consulting Psychologists Press, Palo Alto, Calif., 1968.

[^4]: Datos proporcionados por Darlene Gordon, School of Education, Purdue University. Estadistica aplicada básica.  David. S. Moore.
